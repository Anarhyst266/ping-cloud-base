apiVersion: v1
kind: ConfigMap
metadata:
  name: upload-script
data:
  upload.sh: |-
    #!/bin/sh
    set -x

    # Install AWS CLI if the upload location is S3
    if test -z "${S3_CSD_ARCHIVES_BUCKET}"; then
      echo "Upload location not provided"
      exit 0
    else
      echo "Installing AWS CLI"
      apk --update add python3
      pip3 install --no-cache-dir --upgrade pip
      pip3 install --no-cache-dir --upgrade awscli
    fi

    # Install kubectl
    echo "Installing kubectl"
    curl https://storage.googleapis.com/kubernetes-release/release/v1.15.0/bin/linux/amd64/kubectl -o /usr/local/bin/kubectl
    chmod +x /usr/local/bin/kubectl

    NUM_REPLICAS=$(kubectl get statefulset "${K8S_STATEFUL_SET_NAME}" -o jsonpath='{.spec.replicas}')

    START=0
    END=$((${NUM_REPLICAS} - 1))

    # Run from the target directory so the tar copy works with just a filename.
    TARGET_DIR=/tmp
    cd "${TARGET_DIR}"

    FORMAT="+%d/%b/%Y:%H:%M:%S %z"
    NOW=$(date "${FORMAT}")
    AN_HOUR_AGO=$(date --date="@$(($(date +%s) - 3600))" "${FORMAT}")

    for i in $(seq ${START} ${END}); do
      SERVER="${K8S_STATEFUL_SET_NAME}-${i}"

      # FIXME: In 8.0, use the --duration 1h argument to collect-support-data instead of --timeRange
      "${SERVER_BITS_DIR}/bin/schedule-exec-task" \
        --useSSL --trustAll \
        --hostname "${SERVER}.${K8S_STATEFUL_SET_SERVICE_NAME}" \
        --port ${LDAPS_PORT} \
        --bindDN "${ROOT_USER_DN}" \
        --bindPasswordFile "${ROOT_USER_PASSWORD_FILE}" \
        --waitForCompletion \
        --logCommandOutput \
        "${SERVER_ROOT_DIR}/bin/collect-support-data" \
        "--timeRange" "\"${AN_HOUR_AGO},${NOW}\""

      CSD_OUT=$(kubectl exec "${SERVER}" -- find "${SERVER_ROOT_DIR}" -name support\*zip -type f | sort | tail -1)
      if test -z "${CSD_OUT}"; then
        echo "No support data archive found on ${SERVER}"
        continue
      fi

      SRC_FILE="${SERVER}:${CSD_OUT}"
      DST_FILE=$(basename "${CSD_OUT}")

      echo "Copying ${SRC_FILE} to ${TARGET_DIR}/${DST_FILE}"
      kubectl cp "${SRC_FILE}" "${DST_FILE}"

      echo "Removing ${SRC_FILE} from the server"
      kubectl exec "${SERVER}" -- rm -f "${CSD_OUT}"

      echo "Done copying CSD from server ${SERVER}"

      # FIXME: upload to S3
      echo "Uploading "${DST_FILE}" to ${S3_CSD_ARCHIVES_BUCKET}"
      # aws s3 cp "${DST_FILE}" "${S3_CSD_ARCHIVES_BUCKET}"
    done

---

# Perform a CSD upload every hour.
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: ds-periodic-csd-upload
spec:
  schedule: "0 */1 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccount: pd-serviceaccount
          restartPolicy: Never
          containers:
          - name: ds-csd-uploader
            # FIXME: switch to stable image before GA
            image: pingidentity/pingdirectory:edge
            command:
            - /opt/in/upload.sh
            volumeMounts:
            - name: passwords
              mountPath: /usr/local/secrets
              readOnly: true
            - name: upload-script
              mountPath: /opt/in/upload.sh
              subPath: upload.sh
            env:
            - name: K8S_STATEFUL_SET_NAME
              value: $(K8S_STATEFUL_SET_NAME)
            - name: K8S_STATEFUL_SET_SERVICE_NAME
              value: $(K8S_STATEFUL_SET_SERVICE_NAME)
            envFrom:
            - configMapRef:
                name: pingdirectory-environment-variables
          volumes:
          - name: passwords
            secret:
              secretName: pingdirectory-passwords
              defaultMode: 0400
          - name: upload-script
            configMap:
              name: upload-script
              defaultMode: 0555